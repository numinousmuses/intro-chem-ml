{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/joshuaokolo/introductory-chemistry-research-ml?scriptVersionId=104196430\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"#Here we install the package. For me it's been a nightmare to install rdkit into Kaggle's environment. \n#But wonderful Kaggle's technical support helped me to find the way.\n\n!conda install -y -c rdkit rdkit;\n!pip install pandas==0.23.0","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's load the data and look at them\ndf= pd.read_csv('../input/mlchem/logP_dataset.csv', names=['smiles', 'logP'])\ndf.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Importing Chem module\nfrom rdkit import Chem \n\n#Method transforms smiles strings to mol rdkit object\ndf['mol'] = df['smiles'].apply(lambda x: Chem.MolFromSmiles(x)) \n\n#Now let's see what we've got\nprint(type(df['mol'][0]))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from rdkit.Chem import Draw\nmols = df['mol'][:20]\n\n#MolsToGridImage allows to paint a number of molecules at a time\nDraw.MolsToGridImage(mols, molsPerRow=5, useSVG=True, legends=list(df['smiles'][:20].values))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# AddHs function adds H atoms to a MOL (as Hs in SMILES are usualy ignored)\n# GetNumAtoms() method returns a general nubmer of all atoms in a molecule\n# GetNumHeavyAtoms() method returns a nubmer of all atoms in a molecule with molecular weight > 1\n\n\ndf['mol'] = df['mol'].apply(lambda x: Chem.AddHs(x))\ndf['num_of_atoms'] = df['mol'].apply(lambda x: x.GetNumAtoms())\ndf['num_of_heavy_atoms'] = df['mol'].apply(lambda x: x.GetNumHeavyAtoms())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nsns.jointplot(df.num_of_atoms, df.logP)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# First we need to settle the pattern.\nc_patt = Chem.MolFromSmiles('C')\n\n# Now let's implement GetSubstructMatches() method\nprint(df['mol'][0].GetSubstructMatches(c_patt))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#We're going to settle the function that searches patterns and use it for a list of most common atoms only\ndef number_of_atoms(atom_list, df):\n    for i in atom_list:\n        df['num_of_{}_atoms'.format(i)] = df['mol'].apply(lambda x: len(x.GetSubstructMatches(Chem.MolFromSmiles(i))))\n\nnumber_of_atoms(['C','O', 'N', 'Cl'], df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(df[['num_of_atoms','num_of_C_atoms','num_of_N_atoms', 'num_of_O_atoms', 'logP']], diag_kind='kde', kind='reg', markers='+')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import RidgeCV\nfrom sklearn.model_selection import train_test_split\n\n#Leave only features columns\ntrain_df = df.drop(columns=['smiles', 'mol', 'logP'])\ny = df['logP'].values\n\nprint(train_df.columns)\n\n#Perform a train-test split. We'll use 10% of the data to evaluate the model while training on 90%\n\nX_train, X_test, y_train, y_test = train_test_split(train_df, y, test_size=.1, random_state=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error, mean_squared_error\ndef evaluation(model, X_test, y_test):\n    prediction = model.predict(X_test)\n    mae = mean_absolute_error(y_test, prediction)\n    mse = mean_squared_error(y_test, prediction)\n    \n    plt.figure(figsize=(15, 10))\n    plt.plot(prediction[:300], \"red\", label=\"prediction\", linewidth=1.0)\n    plt.plot(y_test[:300], 'green', label=\"actual\", linewidth=1.0)\n    plt.legend()\n    plt.ylabel('logP')\n    plt.title(\"MAE {}, MSE {}\".format(round(mae, 4), round(mse, 4)))\n    plt.show()\n    \n    print('MAE score:', round(mae, 4))\n    print('MSE score:', round(mse,4))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Train the model\nridge = RidgeCV(cv=5)\nridge.fit(X_train, y_train)\n#Evaluate results\nevaluation(ridge, X_test, y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"atp = Chem.MolFromSmiles('C1=NC2=C(C(=N1)N)N=CN2[C@H]3[C@@H]([C@@H]([C@H](O3)COP(=O)(O)OP(=O)(O)OP(=O)(O)O)O)O')\n\n# Getting number of rings with specified number of backbones\nprint('Number of rings with 1 backbone:', atp.GetRingInfo().NumAtomRings(1))\nprint('Number of rings with 2 backbones:', atp.GetRingInfo().NumAtomRings(2))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m = Chem.MolFromSmiles('C(=O)C(=N)CCl')\n#Iterating through atoms to get atom symbols and explicit valencies \nfor atom in m.GetAtoms():\n    print('Atom:', atom.GetSymbol(), 'Valence:', atom.GetExplicitValence())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from rdkit.Chem import Descriptors\ndf['tpsa'] = df['mol'].apply(lambda x: Descriptors.TPSA(x))\ndf['mol_w'] = df['mol'].apply(lambda x: Descriptors.ExactMolWt(x))\ndf['num_valence_electrons'] = df['mol'].apply(lambda x: Descriptors.NumValenceElectrons(x))\ndf['num_heteroatoms'] = df['mol'].apply(lambda x: Descriptors.NumHeteroatoms(x))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = df.drop(columns=['smiles', 'mol', 'logP'])\ny = df['logP'].values\n\nprint(train_df.columns)\n\n#Perform a train-test split. We'll use 10% of the data to evaluate the model while training on 90%\n\nX_train, X_test, y_train, y_test = train_test_split(train_df, y, test_size=.1, random_state=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Train the model\nridge = RidgeCV(cv=5)\nridge.fit(X_train, y_train)\n#Evaluate results and plot predictions\nevaluation(ridge, X_test, y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Installing a package\n!pip install git+https://github.com/samoturk/mol2vec;","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Load the dataset and extract target values\nmdf= pd.read_csv('../input/mlchem/logP_dataset.csv', names=['smiles', \n                                           'target'])\ntarget = mdf['target']\nmdf.drop(columns='target',inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Transforming SMILES to MOL\nmdf['mol'] = mdf['smiles'].apply(lambda x: Chem.MolFromSmiles(x))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Loading pre-trained model via word2vec\nfrom gensim.models import word2vec\nmodel = word2vec.Word2Vec.load('../input/mlchem/model_300dim.pkl')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mol2vec.features import mol2alt_sentence, mol2sentence, MolSentence, DfVec, sentences2vec\nfrom gensim.models import word2vec\nprint('Molecular sentence:', mol2alt_sentence(mdf['mol'][1], radius=1))\nprint('\\nMolSentence object:', MolSentence(mol2alt_sentence(mdf['mol'][1], radius=1)))\nprint('\\nDfVec object:',DfVec(sentences2vec(MolSentence(mol2alt_sentence(mdf['mol'][1], radius=1)), model, unseen='UNK')))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Constructing sentences\nmdf['sentence'] = mdf.apply(lambda x: MolSentence(mol2alt_sentence(x['mol'], 1)), axis=1)\n\n#Extracting embeddings to a numpy.array\n#Note that we always should mark unseen='UNK' in sentence2vec() so that model is taught how to handle unknown substructures\nmdf['mol2vec'] = [DfVec(x) for x in sentences2vec(mdf['sentence'], model, unseen='UNK')]\nX = np.array([x.vec for x in mdf['mol2vec']])\ny = target.values\n\nX.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.1, random_state=1)\nridge = RidgeCV(cv=5)\nridge.fit(X_train, y_train)\nevaluation(ridge, X_test, y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mdf = pd.DataFrame(X)\nnew_df = pd.concat((mdf, train_df), axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(new_df, y, test_size=.1, random_state=1)\nridge = RidgeCV(cv=5)\nridge.fit(X_train, y_train)\nevaluation(ridge, X_test, y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Classification with HIV dataset\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n#Read the data\nhiv = pd.read_csv('../input/mlchem/HIV.csv')\nhiv.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's look at the target values count\nsns.countplot(data = hiv, x='HIV_active', orient='v')\nplt.ylabel('HIM active')\nplt.xlabel('Count of values')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Transform SMILES to MOL\nhiv['mol'] = hiv['smiles'].apply(lambda x: Chem.MolFromSmiles(x)) \n\n#Extract descriptors\nhiv['tpsa'] = hiv['mol'].apply(lambda x: Descriptors.TPSA(x))\nhiv['mol_w'] = hiv['mol'].apply(lambda x: Descriptors.ExactMolWt(x))\nhiv['num_valence_electrons'] = hiv['mol'].apply(lambda x: Descriptors.NumValenceElectrons(x))\nhiv['num_heteroatoms'] = hiv['mol'].apply(lambda x: Descriptors.NumHeteroatoms(x))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = hiv.HIV_active.values\nX = hiv.drop(columns=['smiles', 'activity','HIV_active', 'mol'])\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.20, random_state=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import auc, roc_curve\ndef evaluation_class(model, X_test, y_test):\n    prediction = model.predict_proba(X_test)\n    preds = model.predict_proba(X_test)[:,1]\n    fpr, tpr, threshold = roc_curve(y_test, preds)\n    roc_auc = auc(fpr, tpr)\n    \n    plt.title('ROC Curve')\n    plt.plot(fpr, tpr, 'g', label = 'AUC = %0.3f' % roc_auc)\n    plt.legend(loc = 'lower right')\n    plt.plot([0, 1], [0, 1],'r--')\n    plt.xlim([0, 1])\n    plt.ylim([0, 1])\n    plt.ylabel('True Positive Rate')\n    plt.xlabel('False Positive Rate')\n    plt.show()\n    \n    print('ROC AUC score:', round(roc_auc, 4))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\n\nX_train = StandardScaler().fit_transform(X_train)\nX_test = StandardScaler().fit_transform(X_test)\n\nlr = LogisticRegression()\nlr.fit(X_train, y_train)\n\nevaluation_class(lr, X_test, y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Constructing sentences\nhiv['sentence'] = hiv.apply(lambda x: MolSentence(mol2alt_sentence(x['mol'], 1)), axis=1)\n\n#Extracting embeddings to a numpy.array\n#Note that we always should mark unseen='UNK' in sentence2vec() so that model is taught how to handle unknown substructures\nhiv['mol2vec'] = [DfVec(x) for x in sentences2vec(hiv['sentence'], model, unseen='UNK')]\nX_mol = np.array([x.vec for x in hiv['mol2vec']])\nX_mol = pd.DataFrame(X_mol)\n\n#Concatenating matrices of features\nnew_hiv = pd.concat((X, X_mol), axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(new_hiv, y, test_size=.20, random_state=1)\n\nX_train = StandardScaler().fit_transform(X_train)\nX_test = StandardScaler().fit_transform(X_test)\n\nlr = LogisticRegression()\nlr.fit(X_train, y_train)\n\nevaluation_class(lr, X_test, y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**References:**\n\n* Kaggle Datasets: LogP of Chemical Structures. https://www.kaggle.com/matthewmasters/chemical-structure-and-logp\n\n* Jaeger, S., Fulle, S., & Turk, S. (2018). Mol2vec: Unsupervised machine learning approach with chemical intuition. Journal of chemical information and modeling, 58(1), 27-35. URL = {http://dx.doi.org/10.1021/acs.jcim.7b00616}, eprint = {http://dx.doi.org/10.1021/acs.jcim.7b00616}\n\n* AIDS Antiviral Screen Data. https://wiki.nci.nih.gov/display/NCIDTPdata/AIDS+Antiviral+Screen+Data","metadata":{}}]}